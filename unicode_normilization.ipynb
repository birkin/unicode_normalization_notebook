{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05c1d464",
   "metadata": {},
   "source": [
    "# unicode trickiness\n",
    "\n",
    "## The problem...\n",
    "\n",
    "You feel you're on top of unicode, because all your database-data is encoded in utf-8, and your search-terms are encoded in utf-8, and internally you're decoding to unicode for everything -- all-good. But... you have a search term, and you _know_ the search term is in the database, yet no match is found!!\n",
    "\n",
    "Example...\n",
    "\n",
    "```\n",
    ">>> database_words\n",
    "['hola', 'más', 'qué']\n",
    ">>> \n",
    ">>> 'foo' in database_words\n",
    "False\n",
    ">>> \n",
    ">>> 'hola' in database_words\n",
    "True\n",
    ">>> \n",
    ">>> 'más' in database_words  # search word typed in via mac 'option-e, a' method\n",
    "True\n",
    ">>> \n",
    ">>> 'qué' in database_words  # search word typed in via mac 'option-e, e' method\n",
    "False  # ???\n",
    ">>> \n",
    "```\n",
    "\n",
    "The above confusing situation is because in the 'database' (`database_words`), the last word's accented-letter is two combined unicode-characters, but the search-term is using a single unicode-character for the accented letter.\n",
    "\n",
    "Here's how `database_words` was created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76b0e578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hola', 'más', 'qué']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_words = ['hola', 'm' + '\\u00e1' + 's', 'qu' + '\\u0065' + '\\u0301']\n",
    "\n",
    "database_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943f35c3",
   "metadata": {},
   "source": [
    "And this is how you'd explicitly create the single unicode-character search term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbb7edae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qué'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'qu' + '\\u00e9'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50d8f3c",
   "metadata": {},
   "source": [
    "(On the Mac, that accented-e is created via typing `option-e` then `e`, which produces the above single-unicode character.)\n",
    "\n",
    "There is no way, just by looking, that you can tell the true nature of that accented 'e'.\n",
    "\n",
    "\n",
    "## examining characters, if curious...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "549d5399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unicode-name, ``LATIN SMALL LETTER Q``\n",
      "unicode-name, ``LATIN SMALL LETTER U``\n",
      "unicode-name, ``LATIN SMALL LETTER E WITH ACUTE``\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "for c in 'qué':  # typed in via option-e method which produces `'qu' + '\\u00e9'`\n",
    "    print( f'unicode-name, ``{unicodedata.name(c)}``' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f94b05d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unicode-name, ``LATIN SMALL LETTER Q``\n",
      "unicode-name, ``LATIN SMALL LETTER U``\n",
      "unicode-name, ``LATIN SMALL LETTER E``\n",
      "unicode-name, ``COMBINING ACUTE ACCENT``\n"
     ]
    }
   ],
   "source": [
    "for c in 'qué':  # pasted in from database_words, which uses the two combined unicode-characters: `'qu' + '\\u0065' + '\\u0301'`\n",
    "    print( f'unicode-name, ``{unicodedata.name(c)}``' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c8ad90",
   "metadata": {},
   "source": [
    "## Dealing with this weird reality...\n",
    "\n",
    "_Good tools, like solr, often enable you to not have to worry about this -- a search-term with characters composed one way will generally find content composed the other way._\n",
    "\n",
    "If you normalize-->decompose data in the database, and normalize-->decompose the search term, all will work.\n",
    "\n",
    "The code below normalizes by decomposing single-unicode characters into multiple-unicode characters. Note that we start with the single unicode-character, and transform it into the two combined unicode-characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "673d680a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unicode-name, ``LATIN SMALL LETTER Q``\n",
      "unicode-name, ``LATIN SMALL LETTER U``\n",
      "unicode-name, ``LATIN SMALL LETTER E``\n",
      "unicode-name, ``COMBINING ACUTE ACCENT``\n"
     ]
    }
   ],
   "source": [
    "decomposed_output = unicodedata.normalize( 'NFKD', 'qu' + '\\u00e9' )\n",
    "\n",
    "for c in decomposed_output:\n",
    "    print( f'unicode-name, ``{unicodedata.name(c)}``' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b153dc35",
   "metadata": {},
   "source": [
    "## So one overall solution... \n",
    "\n",
    "Save data in a normalized-->decomposed way..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f465c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hola', 'más', 'qué']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decomposed_database_words = []\n",
    "\n",
    "for word in database_words:\n",
    "    decomposed_word = unicodedata.normalize( 'NFKD', word )\n",
    "    decomposed_database_words.append( decomposed_word )\n",
    "\n",
    "decomposed_database_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6c44b3",
   "metadata": {},
   "source": [
    "...and then normalize-->decompose the search-term..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe57ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = 'qu' + '\\u00e9'  # demonstrates search term starts with the single unicode character\n",
    "decomposed_search_term = unicodedata.normalize( 'NFKD', search_term )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37afa98",
   "metadata": {},
   "source": [
    "...then the normalized-->decomposed search term will find the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f7055f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decomposed_search_term in decomposed_database_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cc2e06",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
